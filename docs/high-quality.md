# How to get high-quality annotations

> What can I do if IAA is low?
There may be several reasons why your annotators do not agree on the annotation tasks. It is important to mitigate these risks as soon as possible by identifying the causes. If you find such a scenario we recommend you review the following:

Guidelines are key. If you have a large group of annotators not agreeing on a specific annotation task, it means your guidelines for this task are not clearly defined. Try to provide representative examples for different scenarios, discuss boundary cases and remove ambiguity. Remember, you can attach pictures or screenshots to the guidelines.

Be specific. If annotation tasks are too broadly defined or ambiguous, there is room for different interpretations, and eventually disagreement. On the other hand, very rich and granular tasks can be difficult for annotators to annotate accurately. Depending on the scope of your project, find the best trade-off between high specific annotations and affordable annotations.

* Test reliability

Before start annotating large amounts of data, it is good idea to make several assessments with a sample of the data. Once the team members have annotated this data, check the IAA and improve your guidelines or train your team accordingly.

Train. Make sure you appropriately train members joining the annotation project. If you find annotators that do not agree with most of members from the team, check the reasons, make your guidelines evolve and train them further.

Check how heterogeneous your data is. If your data/documents are very different from each other either in complexity or structure, a larger effort would be required to stabilize the agreement. We recommend splitting the data into homogeneous groups.

You can create a separate project with the same setup as your production project and perform tests. If you bring someone onboard, you can have them annotate the test documents already annotated by the team and check the level of agreement. To train your team, you can add new documents and check the team agreement.

* Adjudication

When different users annotate the same documents, as a result, there are multiple annotation versions. Adjudication is the process to resolve inconsistencies among these versions before promoting a version to gold standard. 